{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character Based GRU RNN model for Text Generation using NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmWlwIC543IQjR5FsC2pHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panimesh14/Natural-Language-Processing-NLP/blob/main/Character_Based_GRU_RNN_model_for_Text_Generation_using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU RNN based Text Generator Model"
      ],
      "metadata": {
        "id": "0Aovo1_ra4RC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v7mLkyaBwPhX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as put\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Reading\n",
        "bookfile_path=\"shakespeare.txt\";#path to file\n",
        "booktext=open(bookfile_path,'r').read();#reading text from book\n",
        "booktext[100:500]#random text from book"
      ],
      "metadata": {
        "id": "i3T78BdWz0IR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "a61e9619-37ad-442f-e4db-c6da87ed2caf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ght never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vocab/Unique words\n",
        "vocab=sorted(set(booktext));\n",
        "len(vocab)"
      ],
      "metadata": {
        "id": "ohVT7QLK4t-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3045cd79-bbf3-4d6d-8618-6d1d5d114d32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Character and Index Map\n",
        "#Vocab conversion to dictionary\n",
        "char_to_ind={char:ind for ind,char in enumerate(vocab)}\n",
        "ind_to_char={ind:char for ind,char in enumerate(vocab)}\n",
        "ind_to_char"
      ],
      "metadata": {
        "id": "xcFvnwW15UbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d27382-5e89-445e-dc0a-56b504f30b90"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '\"',\n",
              " 4: '&',\n",
              " 5: \"'\",\n",
              " 6: '(',\n",
              " 7: ')',\n",
              " 8: ',',\n",
              " 9: '-',\n",
              " 10: '.',\n",
              " 11: '0',\n",
              " 12: '1',\n",
              " 13: '2',\n",
              " 14: '3',\n",
              " 15: '4',\n",
              " 16: '5',\n",
              " 17: '6',\n",
              " 18: '7',\n",
              " 19: '8',\n",
              " 20: '9',\n",
              " 21: ':',\n",
              " 22: ';',\n",
              " 23: '<',\n",
              " 24: '>',\n",
              " 25: '?',\n",
              " 26: 'A',\n",
              " 27: 'B',\n",
              " 28: 'C',\n",
              " 29: 'D',\n",
              " 30: 'E',\n",
              " 31: 'F',\n",
              " 32: 'G',\n",
              " 33: 'H',\n",
              " 34: 'I',\n",
              " 35: 'J',\n",
              " 36: 'K',\n",
              " 37: 'L',\n",
              " 38: 'M',\n",
              " 39: 'N',\n",
              " 40: 'O',\n",
              " 41: 'P',\n",
              " 42: 'Q',\n",
              " 43: 'R',\n",
              " 44: 'S',\n",
              " 45: 'T',\n",
              " 46: 'U',\n",
              " 47: 'V',\n",
              " 48: 'W',\n",
              " 49: 'X',\n",
              " 50: 'Y',\n",
              " 51: 'Z',\n",
              " 52: '[',\n",
              " 53: ']',\n",
              " 54: '_',\n",
              " 55: '`',\n",
              " 56: 'a',\n",
              " 57: 'b',\n",
              " 58: 'c',\n",
              " 59: 'd',\n",
              " 60: 'e',\n",
              " 61: 'f',\n",
              " 62: 'g',\n",
              " 63: 'h',\n",
              " 64: 'i',\n",
              " 65: 'j',\n",
              " 66: 'k',\n",
              " 67: 'l',\n",
              " 68: 'm',\n",
              " 69: 'n',\n",
              " 70: 'o',\n",
              " 71: 'p',\n",
              " 72: 'q',\n",
              " 73: 'r',\n",
              " 74: 's',\n",
              " 75: 't',\n",
              " 76: 'u',\n",
              " 77: 'v',\n",
              " 78: 'w',\n",
              " 79: 'x',\n",
              " 80: 'y',\n",
              " 81: 'z',\n",
              " 82: '|',\n",
              " 83: '}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind#Character to Index Map"
      ],
      "metadata": {
        "id": "vvqDAC4Zqw6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73db74ec-e981-4312-ba43-4925323d2be7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Text Encoding of character to index\n",
        "encoding_text=np.array([char_to_ind[char] for char in booktext])\n",
        "print(encoding_text.shape)\n",
        "encoding_text\n",
        "#~5.45 million sample characters or encoded character tokens"
      ],
      "metadata": {
        "id": "5oLjV-v3rCtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9dc6a10-528b-4551-e90a-baa2425fd042"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5445609,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sequence Length and batches\n",
        "booktext[:170]\n",
        "#sequence length should be sufficient to capture some logical trends for prediction"
      ],
      "metadata": {
        "id": "9ZPFCqUBsccR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e874fd87-2352-471b-8131-90eb8bcd0a2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Sequence Generation"
      ],
      "metadata": {
        "id": "k_SPPZugVyKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len=512;#somewhat random but given above text, it seems enough\n",
        "num_seq=len(booktext)//(seq_len+1);#adding 1 for 0 index\n",
        "num_seq"
      ],
      "metadata": {
        "id": "goyXDakquwAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc068a10-0271-4ee9-a5e0-e92922ee6bd0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10615"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Text Sequence Generation#Text Series Generator\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoding_text);\n",
        "sequences=char_dataset.batch(seq_len+1,drop_remainder=True)#dropping remainder to account for remainder in number of sequences"
      ],
      "metadata": {
        "id": "RFPppOsHvUEP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#For indexed text matching and loss calculation after character prediction \n",
        "def target_series_gen(seq):#for matching and loss calculation\n",
        "    input_txt=seq[:-1];\n",
        "    target_txt=seq[1:];\n",
        "    return input_txt,target_txt\n",
        "#Text Series Generator predicting next character from a given series\n",
        "#(X,y) tuple pair generation function"
      ],
      "metadata": {
        "id": "6z-JFyMT8e2u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Indexed Text Series Generation from sequence\n",
        "indexed_dataset=sequences.map(target_series_gen)#text series generator tuple of input text and corresponding text after character prediction\n",
        "batch_size=1;\n",
        "buffer_size=1000;\n",
        "indexed_dataset = indexed_dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
      ],
      "metadata": {
        "id": "abABigv39X3T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL BUILDING\n",
        "embed_dim=len(vocab);#taking the entire vocabulary for embedding, less can be taken and would be less computationally expensive\n",
        "hidden_state=1024;"
      ],
      "metadata": {
        "id": "PKnbkNpv_Vqv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For function call from model\n",
        "#For function calls as sparse_categorical_crossentropy cannot be modified inside function\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "def sparse_cat_crossentropy_loss(y_true,y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
      ],
      "metadata": {
        "id": "Smh6AVIOA4g-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Dense\n",
        "def text_model(vocab_size,embed_dim,hidden_state,batch_size):\n",
        "    char_level_model=Sequential()\n",
        "    char_level_model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "    char_level_model.add(GRU(hidden_state,return_sequences=True, stateful=True))\n",
        "    char_level_model.add(Dense(vocab_size))\n",
        "    char_level_model.compile(optimizer='adam',loss=sparse_cat_crossentropy_loss)#since sparse categorical cross entropy could not be modified inside the function for logits=True\n",
        "    return char_level_model"
      ],
      "metadata": {
        "id": "l4kRs8z5BvDq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_gen_model=text_model(len(vocab),embed_dim,hidden_state,batch_size)\n",
        "text_gen_model.summary()\n",
        "#~3.5 million weight parameters for learning"
      ],
      "metadata": {
        "id": "3NVTYCVnGTM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f74fdd0-4e8c-4b1e-fd1c-d561d7434e31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (1, None, 84)             7056      \n",
            "                                                                 \n",
            " gru (GRU)                   (1, None, 1024)           3409920   \n",
            "                                                                 \n",
            " dense (Dense)               (1, None, 84)             86100     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,503,076\n",
            "Trainable params: 3,503,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking just random sample output and shape\n",
        "sample_size=1;\n",
        "for input_sample_batch,output_sample_batch in indexed_dataset.take(sample_size):\n",
        "    model_pred_sample_batch=text_gen_model(input_sample_batch);\n",
        "model_pred_sample_batch.shape"
      ],
      "metadata": {
        "id": "nhwEcDqoOCTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7719584f-d832-4f71-920c-f60f10c77894"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 512, 84])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_pred_sample_batch[0]#Model returns logits/log odds probability of occurrence of any character in vocab at every character position of sequence\n",
        "#probability distribution vectors of size of vocab at each character position \n",
        "#size therefore=seq_lengthxvocab_size"
      ],
      "metadata": {
        "id": "-dxSYNmGPQMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b3d397-0044-4199-e4ad-d410f84bdb7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(512, 84), dtype=float32, numpy=\n",
              "array([[ 0.00231476, -0.00675318,  0.00972144, ..., -0.00211171,\n",
              "         0.00271326, -0.00448302],\n",
              "       [ 0.00400221, -0.00912479,  0.01355366, ..., -0.00364586,\n",
              "         0.00323259, -0.00636193],\n",
              "       [ 0.0050957 , -0.00979108,  0.01504654, ..., -0.00455231,\n",
              "         0.00311726, -0.0072171 ],\n",
              "       ...,\n",
              "       [-0.00297844,  0.00301474, -0.00456339, ...,  0.00336004,\n",
              "         0.00949498, -0.0029708 ],\n",
              "       [-0.00417688,  0.00088109, -0.01027511, ...,  0.00990327,\n",
              "         0.00343948, -0.00214919],\n",
              "       [ 0.00206069,  0.00189897,  0.00345223, ...,  0.00521082,\n",
              "         0.00479259,  0.00538615]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_indices=tf.random.categorical(model_pred_sample_batch[0],num_samples=1)#number of sample =1 as the most probable character is to be extracted\n",
        "#converting probability distribution at each character position to index with max probability character being output\n",
        "sample_indices"
      ],
      "metadata": {
        "id": "7T9ka9TQQV_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d29a12d-8340-47d6-be49-d211697666d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(512, 1), dtype=int64, numpy=\n",
              "array([[15],\n",
              "       [18],\n",
              "       [15],\n",
              "       [73],\n",
              "       [57],\n",
              "       [ 4],\n",
              "       [21],\n",
              "       [79],\n",
              "       [72],\n",
              "       [44],\n",
              "       [ 3],\n",
              "       [30],\n",
              "       [73],\n",
              "       [60],\n",
              "       [81],\n",
              "       [22],\n",
              "       [21],\n",
              "       [45],\n",
              "       [17],\n",
              "       [54],\n",
              "       [26],\n",
              "       [35],\n",
              "       [58],\n",
              "       [80],\n",
              "       [17],\n",
              "       [ 1],\n",
              "       [13],\n",
              "       [69],\n",
              "       [63],\n",
              "       [31],\n",
              "       [73],\n",
              "       [11],\n",
              "       [52],\n",
              "       [ 3],\n",
              "       [ 6],\n",
              "       [49],\n",
              "       [57],\n",
              "       [ 3],\n",
              "       [55],\n",
              "       [55],\n",
              "       [58],\n",
              "       [30],\n",
              "       [52],\n",
              "       [35],\n",
              "       [16],\n",
              "       [29],\n",
              "       [70],\n",
              "       [59],\n",
              "       [24],\n",
              "       [ 2],\n",
              "       [17],\n",
              "       [80],\n",
              "       [65],\n",
              "       [82],\n",
              "       [14],\n",
              "       [78],\n",
              "       [57],\n",
              "       [10],\n",
              "       [10],\n",
              "       [61],\n",
              "       [31],\n",
              "       [83],\n",
              "       [ 6],\n",
              "       [59],\n",
              "       [38],\n",
              "       [46],\n",
              "       [41],\n",
              "       [25],\n",
              "       [82],\n",
              "       [ 8],\n",
              "       [73],\n",
              "       [37],\n",
              "       [66],\n",
              "       [51],\n",
              "       [32],\n",
              "       [43],\n",
              "       [59],\n",
              "       [40],\n",
              "       [77],\n",
              "       [ 3],\n",
              "       [81],\n",
              "       [ 9],\n",
              "       [18],\n",
              "       [ 0],\n",
              "       [45],\n",
              "       [64],\n",
              "       [74],\n",
              "       [54],\n",
              "       [61],\n",
              "       [76],\n",
              "       [53],\n",
              "       [63],\n",
              "       [ 6],\n",
              "       [ 2],\n",
              "       [13],\n",
              "       [76],\n",
              "       [13],\n",
              "       [13],\n",
              "       [ 4],\n",
              "       [68],\n",
              "       [17],\n",
              "       [19],\n",
              "       [63],\n",
              "       [65],\n",
              "       [28],\n",
              "       [17],\n",
              "       [47],\n",
              "       [32],\n",
              "       [ 4],\n",
              "       [17],\n",
              "       [ 0],\n",
              "       [ 1],\n",
              "       [ 3],\n",
              "       [21],\n",
              "       [17],\n",
              "       [27],\n",
              "       [22],\n",
              "       [24],\n",
              "       [33],\n",
              "       [24],\n",
              "       [70],\n",
              "       [10],\n",
              "       [43],\n",
              "       [10],\n",
              "       [23],\n",
              "       [82],\n",
              "       [55],\n",
              "       [64],\n",
              "       [72],\n",
              "       [54],\n",
              "       [70],\n",
              "       [25],\n",
              "       [ 2],\n",
              "       [24],\n",
              "       [17],\n",
              "       [24],\n",
              "       [18],\n",
              "       [52],\n",
              "       [ 9],\n",
              "       [ 6],\n",
              "       [70],\n",
              "       [78],\n",
              "       [73],\n",
              "       [21],\n",
              "       [49],\n",
              "       [15],\n",
              "       [27],\n",
              "       [71],\n",
              "       [47],\n",
              "       [71],\n",
              "       [ 9],\n",
              "       [48],\n",
              "       [ 9],\n",
              "       [48],\n",
              "       [27],\n",
              "       [72],\n",
              "       [ 7],\n",
              "       [57],\n",
              "       [ 2],\n",
              "       [32],\n",
              "       [72],\n",
              "       [78],\n",
              "       [13],\n",
              "       [45],\n",
              "       [ 2],\n",
              "       [54],\n",
              "       [22],\n",
              "       [75],\n",
              "       [55],\n",
              "       [32],\n",
              "       [10],\n",
              "       [78],\n",
              "       [80],\n",
              "       [18],\n",
              "       [81],\n",
              "       [83],\n",
              "       [22],\n",
              "       [71],\n",
              "       [52],\n",
              "       [46],\n",
              "       [67],\n",
              "       [28],\n",
              "       [15],\n",
              "       [16],\n",
              "       [21],\n",
              "       [66],\n",
              "       [30],\n",
              "       [ 6],\n",
              "       [58],\n",
              "       [ 8],\n",
              "       [54],\n",
              "       [46],\n",
              "       [67],\n",
              "       [61],\n",
              "       [41],\n",
              "       [80],\n",
              "       [20],\n",
              "       [18],\n",
              "       [24],\n",
              "       [65],\n",
              "       [ 3],\n",
              "       [45],\n",
              "       [41],\n",
              "       [11],\n",
              "       [14],\n",
              "       [34],\n",
              "       [58],\n",
              "       [28],\n",
              "       [49],\n",
              "       [41],\n",
              "       [64],\n",
              "       [30],\n",
              "       [46],\n",
              "       [ 6],\n",
              "       [15],\n",
              "       [73],\n",
              "       [34],\n",
              "       [42],\n",
              "       [71],\n",
              "       [33],\n",
              "       [ 6],\n",
              "       [39],\n",
              "       [51],\n",
              "       [56],\n",
              "       [62],\n",
              "       [41],\n",
              "       [74],\n",
              "       [57],\n",
              "       [10],\n",
              "       [33],\n",
              "       [48],\n",
              "       [ 8],\n",
              "       [54],\n",
              "       [65],\n",
              "       [49],\n",
              "       [35],\n",
              "       [17],\n",
              "       [20],\n",
              "       [60],\n",
              "       [65],\n",
              "       [28],\n",
              "       [51],\n",
              "       [44],\n",
              "       [14],\n",
              "       [66],\n",
              "       [69],\n",
              "       [67],\n",
              "       [22],\n",
              "       [54],\n",
              "       [32],\n",
              "       [70],\n",
              "       [24],\n",
              "       [48],\n",
              "       [76],\n",
              "       [34],\n",
              "       [60],\n",
              "       [69],\n",
              "       [54],\n",
              "       [35],\n",
              "       [25],\n",
              "       [43],\n",
              "       [ 6],\n",
              "       [58],\n",
              "       [50],\n",
              "       [67],\n",
              "       [28],\n",
              "       [22],\n",
              "       [30],\n",
              "       [45],\n",
              "       [ 0],\n",
              "       [13],\n",
              "       [42],\n",
              "       [71],\n",
              "       [36],\n",
              "       [55],\n",
              "       [45],\n",
              "       [74],\n",
              "       [46],\n",
              "       [ 7],\n",
              "       [10],\n",
              "       [80],\n",
              "       [72],\n",
              "       [31],\n",
              "       [10],\n",
              "       [61],\n",
              "       [ 0],\n",
              "       [ 8],\n",
              "       [45],\n",
              "       [82],\n",
              "       [39],\n",
              "       [58],\n",
              "       [ 3],\n",
              "       [37],\n",
              "       [48],\n",
              "       [ 5],\n",
              "       [72],\n",
              "       [34],\n",
              "       [40],\n",
              "       [12],\n",
              "       [55],\n",
              "       [72],\n",
              "       [54],\n",
              "       [23],\n",
              "       [20],\n",
              "       [10],\n",
              "       [64],\n",
              "       [78],\n",
              "       [27],\n",
              "       [28],\n",
              "       [79],\n",
              "       [ 2],\n",
              "       [52],\n",
              "       [11],\n",
              "       [83],\n",
              "       [33],\n",
              "       [ 5],\n",
              "       [15],\n",
              "       [41],\n",
              "       [35],\n",
              "       [46],\n",
              "       [60],\n",
              "       [64],\n",
              "       [79],\n",
              "       [75],\n",
              "       [44],\n",
              "       [15],\n",
              "       [73],\n",
              "       [80],\n",
              "       [67],\n",
              "       [62],\n",
              "       [58],\n",
              "       [34],\n",
              "       [ 1],\n",
              "       [75],\n",
              "       [45],\n",
              "       [64],\n",
              "       [ 6],\n",
              "       [79],\n",
              "       [80],\n",
              "       [40],\n",
              "       [44],\n",
              "       [64],\n",
              "       [16],\n",
              "       [82],\n",
              "       [24],\n",
              "       [66],\n",
              "       [49],\n",
              "       [52],\n",
              "       [28],\n",
              "       [64],\n",
              "       [64],\n",
              "       [33],\n",
              "       [78],\n",
              "       [41],\n",
              "       [22],\n",
              "       [12],\n",
              "       [24],\n",
              "       [33],\n",
              "       [ 0],\n",
              "       [48],\n",
              "       [ 5],\n",
              "       [52],\n",
              "       [83],\n",
              "       [43],\n",
              "       [36],\n",
              "       [66],\n",
              "       [76],\n",
              "       [57],\n",
              "       [49],\n",
              "       [56],\n",
              "       [29],\n",
              "       [82],\n",
              "       [67],\n",
              "       [49],\n",
              "       [67],\n",
              "       [ 5],\n",
              "       [41],\n",
              "       [ 8],\n",
              "       [16],\n",
              "       [11],\n",
              "       [11],\n",
              "       [37],\n",
              "       [72],\n",
              "       [24],\n",
              "       [12],\n",
              "       [22],\n",
              "       [50],\n",
              "       [19],\n",
              "       [ 4],\n",
              "       [48],\n",
              "       [17],\n",
              "       [24],\n",
              "       [ 0],\n",
              "       [18],\n",
              "       [44],\n",
              "       [16],\n",
              "       [74],\n",
              "       [22],\n",
              "       [39],\n",
              "       [70],\n",
              "       [22],\n",
              "       [76],\n",
              "       [53],\n",
              "       [32],\n",
              "       [70],\n",
              "       [36],\n",
              "       [69],\n",
              "       [ 6],\n",
              "       [25],\n",
              "       [66],\n",
              "       [14],\n",
              "       [57],\n",
              "       [21],\n",
              "       [44],\n",
              "       [60],\n",
              "       [46],\n",
              "       [23],\n",
              "       [61],\n",
              "       [70],\n",
              "       [58],\n",
              "       [ 9],\n",
              "       [ 8],\n",
              "       [ 5],\n",
              "       [41],\n",
              "       [77],\n",
              "       [42],\n",
              "       [24],\n",
              "       [45],\n",
              "       [59],\n",
              "       [23],\n",
              "       [66],\n",
              "       [36],\n",
              "       [31],\n",
              "       [ 8],\n",
              "       [53],\n",
              "       [43],\n",
              "       [68],\n",
              "       [40],\n",
              "       [12],\n",
              "       [ 2],\n",
              "       [40],\n",
              "       [57],\n",
              "       [ 3],\n",
              "       [ 9],\n",
              "       [22],\n",
              "       [36],\n",
              "       [31],\n",
              "       [60],\n",
              "       [28],\n",
              "       [33],\n",
              "       [25],\n",
              "       [52],\n",
              "       [19],\n",
              "       [63],\n",
              "       [59],\n",
              "       [38],\n",
              "       [23],\n",
              "       [ 2],\n",
              "       [41],\n",
              "       [41],\n",
              "       [11],\n",
              "       [14],\n",
              "       [ 0],\n",
              "       [65],\n",
              "       [ 7],\n",
              "       [21],\n",
              "       [27],\n",
              "       [12],\n",
              "       [83],\n",
              "       [26],\n",
              "       [36],\n",
              "       [50],\n",
              "       [ 9],\n",
              "       [15],\n",
              "       [ 1],\n",
              "       [ 0],\n",
              "       [33],\n",
              "       [41],\n",
              "       [34],\n",
              "       [73],\n",
              "       [14],\n",
              "       [14],\n",
              "       [79],\n",
              "       [57],\n",
              "       [13],\n",
              "       [32],\n",
              "       [38],\n",
              "       [ 5],\n",
              "       [ 3],\n",
              "       [46],\n",
              "       [72],\n",
              "       [42],\n",
              "       [19],\n",
              "       [13],\n",
              "       [12],\n",
              "       [60],\n",
              "       [58],\n",
              "       [34],\n",
              "       [26],\n",
              "       [60],\n",
              "       [41],\n",
              "       [61],\n",
              "       [49],\n",
              "       [83],\n",
              "       [50],\n",
              "       [12],\n",
              "       [79],\n",
              "       [43],\n",
              "       [76],\n",
              "       [31],\n",
              "       [39],\n",
              "       [53]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_indices=tf.squeeze(sample_indices,axis=-1).numpy()\n",
        "#Reshaping vector"
      ],
      "metadata": {
        "id": "aqKDHHQTRFyX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_indices[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aHLibDHQdip",
        "outputId": "021be25f-b6b0-49ba-e10d-6f3fa5b46382"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15, 18, 15, 73, 57,  4, 21, 79, 72, 44,  3, 30, 73, 60, 81, 22, 21,\n",
              "       45, 17, 54, 26, 35, 58, 80, 17,  1, 13, 69, 63, 31, 73, 11, 52,  3,\n",
              "        6, 49, 57,  3, 55, 55, 58, 30, 52, 35, 16, 29, 70, 59, 24,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_character=[ind_to_char[ind] for ind in sample_indices]\n",
        "#converting index to character\n",
        "#essentially random output as output is on random untrained model\n",
        "\"\".join(sample_character)\n",
        "#as stated untrained model giving random output"
      ],
      "metadata": {
        "id": "ZGbt3yzaSCkt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9ff5d6f0-7aa8-4044-a712-05eb5c367688"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'474rb&:xqS\"Erez;:T6_AJcy6 2nhFr0[\"(Xb\"``cE[J5Dod>!6yj|3wb..fF}(dMUP?|,rLkZGRdOv\"z-7\\nTis_fu]h(!2u22&m68hjC6VG&6\\n \":6B;>H>o.R.<|`iq_o?!>6>7[-(owr:X4BpVp-W-WBq)b!Gqw2T!_;t`G.wy7z};p[UlC45:kE(c,_UlfPy97>j\"TP03IcCXPiEU(4rIQpH(NZagPsb.HW,_jXJ69ejCZS3knl;_Go>WuIen_J?R(cYlC;ET\\n2QpK`TsU).yqF.f\\n,T|Nc\"LW\\'qIO1`q_<9.iwBCx![0}H\\'4PJUeixtS4rylgcI tTi(xyOSi5|>kX[CiiHwP;1>H\\nW\\'[}RKkubXaD|lXl\\'P,500Lq>1;Y8&W6>\\n7S5s;No;u]GoKn(?k3b:SeU<foc-,\\'PvQ>Td<kKF,]RmO1!Ob\"-;KFeCH?[8hdM<!PP03\\nj):B1}AKY-4 \\nHPIr33xb2GM\\'\"UqQ821ecIAePfX}Y1xRuFN]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL TRAINING\n",
        "text_gen_model.fit(indexed_dataset,epochs=6)"
      ],
      "metadata": {
        "id": "M0Jj1eGGScQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7ba9a9-b8d0-4d69-944f-b7bcc4b1db3a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "10615/10615 [==============================] - 757s 71ms/step - loss: 1.4050\n",
            "Epoch 2/6\n",
            "10615/10615 [==============================] - 760s 72ms/step - loss: 1.1945\n",
            "Epoch 3/6\n",
            "10615/10615 [==============================] - 756s 71ms/step - loss: 1.1652\n",
            "Epoch 4/6\n",
            "10615/10615 [==============================] - 754s 71ms/step - loss: 1.1590\n",
            "Epoch 5/6\n",
            "10615/10615 [==============================] - 758s 71ms/step - loss: 1.3081\n",
            "Epoch 6/6\n",
            "10615/10615 [==============================] - 755s 71ms/step - loss: 1.1864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd76640f710>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text generation/MODEL PREDICTION\n",
        "def generate_text(model,start_seed_text,generation_size=500,temp=1.0):\n",
        "    num_generate=generation_size;\n",
        "    input_eval = [char_to_ind[c] for c in start_seed_text]\n",
        "    input_eval = tf.expand_dims(input_eval,0);\n",
        "    \n",
        "    text_generated=[];\n",
        "    temperature=temp;\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions=model(input_eval)\n",
        "        predictions=tf.squeeze(predictions, axis=0)#reshaping \n",
        "        predictions=predictions/temperature;#probability adjustment \n",
        "        predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()#vector of probability distributions to categorical distribution vector\n",
        "        input_eval=tf.expand_dims([predicted_id],0)#expansion to fit\n",
        "        text_generated.append(ind_to_char[predicted_id])#appending character to text sequence generates\n",
        "    return (start_seed_text+\"\".join(text_generated))#entire text sequence"
      ],
      "metadata": {
        "id": "-ybhKDwzSczc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text_gen_model.build(tf.TensorShape([1,None]))\n",
        "start_seed_text=\"Romeo\";\n",
        "print(generate_text(text_gen_model,start_seed_text,generation_size=1000,temp=1.0));"
      ],
      "metadata": {
        "id": "gendm5oJccNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d8edcf-e638-4076-b232-6ff06ba49333"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Romeogs. So speak, the veignants\n",
            "    Any inso bead-norter bestrayown took like owed,\n",
            "    Thristy his daughter, for attemsats\n",
            "    Rosering ius'd against the replorious\n",
            "      fail, I will diserse swift abrears, for validitions\n",
            "    fame stop our wish! And do any can the chokerabs:\n",
            "    come but me anone, that 'twent not.\n",
            "  Man. A what take his but one ungrace case me lorg,\n",
            "    purenetaditary, bright.\n",
            "  LAUNCE. Sprill, I will not ass welcome.\n",
            "                             Wence Anto\n",
            "  round Atemnon\n",
            "  VALENT I thereriver, to CRIS, and your suret wound, presently\n",
            "       Undersplain, their exit play for a cold direction gorder, for my lord\n",
            "  S. For the bed-shall do worth\n",
            "    in oney-   ho, i' for timptre ha! why, so, I thank you his illy too meet.\n",
            "  SHEPHERD. And would you are frt.\n",
            "    And the Kench charlereted to Rome, nelder\n",
            "  THERMONTERSICEA. By; with othelstand\n",
            "       Enge MROM. O, Liven, sir, their alms\n",
            "\n",
            "  ATHANGLANT\n",
            "\n",
            "\n",
            "         ceptoratur; an oteens here Il, already\n",
            "  APTIMACL beN COMMARDAM O  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EK9lqZx1efeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text generator weights can further be improved by training the model over more epochs and despite the few namely 6 epochs, the results show the model's capability to effectively learn weights."
      ],
      "metadata": {
        "id": "p7Z2bUZBaVZD"
      }
    }
  ]
}